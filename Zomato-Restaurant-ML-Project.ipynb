{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "MSa1f5Uengrz",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "fge-S5ZAYoAp",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Ou-I18pAyIpj",
        "578E2V7j08f6",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "yiiVWRdJDDil",
        "TIqpNgepFxVj",
        "HAih1iBOpsJ2",
        "_-qAgymDpx6N",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Zomato Restaurant Clustering and Sentiment Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**  - Unsupervised Machine Learning\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Sathwik S"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I have worked with Zomato restaurant data to find hidden patterns in restaurant types and customer reviews. I used machine learning to group similar restaurants together (clustering), and natural language processing (NLP) to check how people feel about their experiences (sentiment analysis).\n",
        "\n",
        "This helps in understanding what kind of restaurants are getting positive feedback and what features might influence that. The final goal is to combine both insights to make meaningful conclusions.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/sathwik0404/Zomato-Restaurant-ML-Project"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main challenges I aim to solve in this project:\n",
        "- Group restaurants into similar categories based on features like rating,\n",
        "cost, and type.\n",
        "- Analyze customer reviews to find whether people are generally happy or not.\n",
        "- Combine both these analyses to get deeper insights into what customers prefer and why.\n",
        "\n",
        "This can help restaurant owners, food platforms, or even customers to make better decisions."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata dataset\n",
        "restaurant_df = pd.read_csv(\"/Zomato Restaurant names and Metadata.csv\")\n",
        "\n",
        "# Load reviews dataset\n",
        "review_df = pd.read_csv(\"/Zomato Restaurant reviews.csv\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgfQIvLE5Wha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Restaurant Metadata Preview:\")\n",
        "display(restaurant_df.head())\n",
        "\n",
        "print(\"\\nReviews Dataset Preview:\")\n",
        "display(review_df.head())"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape of the datasets\n",
        "print(\"Restaurant Metadata Shape:\", restaurant_df.shape)\n",
        "print(\"Reviews Dataset Shape:\", review_df.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Restaurant Metadata Info:\")\n",
        "restaurant_df.info()\n",
        "\n",
        "print(\"\\nReviews Dataset Info:\")\n",
        "review_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Duplicate Entries\n",
        "print(\"Duplicate Entries in Restaurant Dataset:\", restaurant_df.duplicated().sum())\n",
        "print(\"Duplicate Entries in Reviews Dataset:\", review_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for Missing/Null Values\n",
        "print(\"Missing Values in Restaurant Dataset:\")\n",
        "print(restaurant_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing Values in Reviews Dataset:\")\n",
        "print(review_df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Missing Values\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(restaurant_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values in Restaurant Dataset\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(review_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title(\"Missing Values in Review Dataset\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?\n",
        "\n",
        "- The **Restaurant Dataset** contains details such as restaurant name, cuisine types, cost, location, etc.\n",
        "- The **Reviews Dataset** includes customer reviews and sentiments for each restaurant.\n",
        "- There are no or very few duplicate entries.\n",
        "- Some missing values exist in certain columns, which will be handled during data preprocessing.\n",
        "- The data types are mostly strings and floats, which suit our analysis.\n",
        "- Overall, the data looks usable and clean enough to proceed with clustering and sentiment analysis.\n",
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column names and data types\n",
        "print(\"Restaurant Dataset Columns & Types:\")\n",
        "print(restaurant_df.dtypes)\n",
        "\n",
        "print(\"\\nReview Dataset Columns & Types:\")\n",
        "print(review_df.dtypes)\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Statistical summary\n",
        "print(\"Restaurant Dataset Summary:\")\n",
        "print(restaurant_df.describe(include='all'))\n",
        "\n",
        "print(\"\\nReview Dataset Summary:\")\n",
        "print(review_df.describe(include='all'))"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The restaurant dataset includes attributes such as restaurant names, location, cuisine, average cost, and ratings.\n",
        "The review dataset contains review text and possibly other fields like restaurant ID, reviewer name, and review date.\n",
        "\n",
        "These variables help in grouping restaurants into clusters (based on cost, location, cuisine, etc.) and understanding customer sentiments from the review texts.\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(restaurant_df.columns)\n"
      ],
      "metadata": {
        "id": "dxXb4UPNXmHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_df.columns)\n"
      ],
      "metadata": {
        "id": "gzxhQZjPXq8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# For restaurant_df\n",
        "print(\"Unique Restaurant Names:\", restaurant_df['Name'].nunique())\n",
        "print(\"Unique Cuisines:\", restaurant_df['Cuisines'].nunique())\n",
        "print(\"Unique Cost Values:\", restaurant_df['Cost'].nunique())\n",
        "\n",
        "# For review_df\n",
        "print(\"\\nUnique Restaurants in Reviews:\", review_df['Restaurant'].nunique())\n",
        "print(\"Sample Unique Reviews:\", review_df['Review'].nunique())\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Wrangling Code\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace these filenames if yours are different\n",
        "review_df = pd.read_csv('/Zomato Restaurant reviews.csv')\n",
        "restaurant_df = pd.read_csv('/Zomato Restaurant names and Metadata.csv')\n"
      ],
      "metadata": {
        "id": "d3HMixvObyv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Data Wrangling\n",
        "\n",
        "\n",
        "# Load both datasets using exact uploaded file names\n",
        "restaurant_df = pd.read_csv(\"/Zomato Restaurant names and Metadata.csv\")\n",
        "review_df = pd.read_csv(\"/Zomato Restaurant reviews.csv\")\n",
        "\n",
        "# Check column names to confirm merge keys\n",
        "print(\"Restaurant Columns:\", restaurant_df.columns)\n",
        "print(\"Review Columns:\", review_df.columns)\n",
        "\n",
        "# Convert names to lowercase for consistent merging\n",
        "restaurant_df['Name'] = restaurant_df['Name'].str.lower()\n",
        "review_df['Restaurant'] = review_df['Restaurant'].str.lower()\n",
        "\n",
        "# Merge the two datasets on restaurant names\n",
        "merged_df = pd.merge(review_df, restaurant_df, left_on='Restaurant', right_on='Name', how='inner')\n",
        "\n",
        "# Show merged dataframe structure and sample\n",
        "display(merged_df.head())\n",
        "display(merged_df.info())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "orfO9t3fKr4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✔ Duplicates and missing values were removed from both datasets to ensure clean inputs.\n",
        "\n",
        "✔ Restaurant names were standardized to lowercase for a proper merge.\n",
        "\n",
        "✔ The review and metadata datasets were merged using the restaurant name, allowing us to connect sentiment data with cost, cuisine, and location.\n",
        "\n",
        "➡ After merging, we get a combined view of what customers think (from reviews) and what type of restaurant they visited — useful for clustering and sentiment analysis later.\n",
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(restaurant_df.columns)\n"
      ],
      "metadata": {
        "id": "HA8RCv5eN2Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(y=restaurant_df['Cuisines'], order=restaurant_df['Cuisines'].value_counts().head(10).index, palette='viridis')\n",
        "plt.title(\"Top 10 Cuisines by Number of Restaurants\")\n",
        "plt.xlabel(\"Number of Restaurants\")\n",
        "plt.ylabel(\"Cuisine Type\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify the areas in the city with the highest concentration of restaurants."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BTM Layout and Indiranagar have the highest number of restaurants, indicating high food demand and commercial activity.Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. Knowing high-density areas can help businesses target expansion zones or avoid oversaturated areas."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "top_cuisines = restaurant_df['Cuisines'].value_counts().head(10)\n",
        "sns.barplot(x=top_cuisines.index, y=top_cuisines.values, palette='magma')\n",
        "plt.title(\"Top 10 Cuisines Offered by Restaurants\")\n",
        "plt.xlabel(\"Cuisine\")\n",
        "plt.ylabel(\"Number of Restaurants\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze the distribution of ratings provided by customers for restaurants"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can identify if most restaurants have high ratings or low ratings, and how skewed the data is."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaurants with lower ratings might need to improve service or food quality. High-rated ones can be promoted more."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(restaurant_df.columns)\n",
        "print(review_df.columns)\n"
      ],
      "metadata": {
        "id": "VScUcga7PGF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(data=restaurant_df, y='Collections', order=restaurant_df['Collections'].value_counts().head(10).index, palette='Set2')\n",
        "plt.title(\"Top 10 Restaurant Collections\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Collection\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find which type of restaurant (like Cafe, Quick Bites, etc.) is most common in the dataset."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see which business models are most popular or dominant in the area."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps decide what type of restaurant might succeed based on market saturation."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "top_cuisines = restaurant_df['Cuisines'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_cuisines.values, y=top_cuisines.index, palette='viridis')\n",
        "plt.title(\"Top 10 Cuisines\")\n",
        "plt.xlabel(\"Number of Restaurants\")\n",
        "plt.ylabel(\"Cuisine\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify the most popular cuisines being served"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll know customer food preferences, which helps in targeting."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps new restaurants decide on menu based on what people already like."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(restaurant_df['Cost'], bins=30, kde=True)\n",
        "plt.title(\"Distribution of Average Cost for Two\")\n",
        "plt.xlabel(\"Average Cost\")\n",
        "plt.ylabel(\"Number of Restaurants\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the price range where most restaurants fall under."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives a view of affordability and pricing strategies"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helps restaurants decide optimal pricing to attract customers"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H₀ (Null): The average ratings of low-cost and high-cost restaurants are equal.\n",
        "\n",
        "H₁ (Alternate): The average ratings of low-cost and high-cost restaurants are not equal."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# 1. Merge both DataFrames on Restaurant Name\n",
        "merged_df = pd.merge(restaurant_df, review_df, left_on='Name', right_on='Restaurant')\n",
        "\n",
        "# 2. Drop missing values\n",
        "merged_df = merged_df.dropna(subset=['Cost', 'Rating'])\n",
        "\n",
        "# 3. Convert types\n",
        "merged_df['Cost'] = pd.to_numeric(merged_df['Cost'], errors='coerce')\n",
        "merged_df['Rating'] = pd.to_numeric(merged_df['Rating'], errors='coerce')\n",
        "\n",
        "# 4. Split the data\n",
        "low_cost = merged_df[merged_df['Cost'] <= 500]['Rating'].dropna()\n",
        "high_cost = merged_df[merged_df['Cost'] > 500]['Rating'].dropna()\n",
        "\n",
        "# 5. Perform independent t-test\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "t_stat, p_val = ttest_ind(low_cost, high_cost, equal_var=False)\n",
        "print(f\"T-Statistic: {t_stat}, P-Value: {p_val}\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent t-test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compare means of two independent groups (low vs high cost). If P-value < 0.05, reject H₀ — there is a significant difference in average ratings between low and high cost restaurants."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H₀ (Null Hypothesis): There is no association between the type of cuisine and sentiment polarity of reviews.\n",
        "\n",
        "H₁ (Alternate Hypothesis): There is a significant association between the type of cuisine and sentiment polarity of reviews.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"restaurant_df columns:\", restaurant_df.columns.tolist())\n",
        "print(\"review_df columns:\", review_df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "lWXLCNMuYGTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Use Main_Cuisine if you created it, or Cuisines directly\n",
        "cuisine_sentiment = pd.crosstab(merged_df['Cuisines'], merged_df['Time'])\n",
        "\n",
        "chi2, p_val, dof, expected = chi2_contingency(cuisine_sentiment)\n",
        "\n",
        "print(f\"Chi-square: {chi2}, P-Value: {p_val}\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JmYHYSrYbRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-square test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because both cuisine type and sentiment category are categorical variables.\n",
        "The Chi-square test is used to determine if there is a significant association between two categorical variables.\n",
        "If p < 0.05, we reject the null hypothesis and conclude that sentiment is associated with cuisine type.\n",
        "\n"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H₀ (Null Hypothesis): There is no significant difference in sentiment scores between reviews with 5-star and 3-star ratings.\n",
        "\n",
        "H₁ (Alternate Hypothesis): Reviews with 5-star ratings have significantly higher sentiment scores than those with 3-star ratings."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Step 1: Convert Rating to numeric to remove issues like 'Like'\n",
        "review_df['Rating'] = pd.to_numeric(review_df['Rating'], errors='coerce')\n",
        "\n",
        "# Step 2: Drop missing (non-numeric or NaN) ratings\n",
        "review_df = review_df.dropna(subset=['Rating'])\n",
        "\n",
        "# Step 3: Make sure 'sentiment_score' exists\n",
        "from textblob import TextBlob\n",
        "\n",
        "def get_sentiment_score(text):\n",
        "    if isinstance(text, str):\n",
        "        return TextBlob(text).sentiment.polarity\n",
        "    return 0\n",
        "\n",
        "review_df['sentiment_score'] = review_df['Review'].apply(get_sentiment_score)\n",
        "\n",
        "# Step 4: Filter sentiment scores for 5-star and 3-star ratings\n",
        "rating_5 = review_df[review_df['Rating'] == 5.0]['sentiment_score'].dropna()\n",
        "rating_3 = review_df[review_df['Rating'] == 3.0]['sentiment_score'].dropna()\n",
        "\n",
        "# Step 5: Perform one-sided t-test\n",
        "from scipy.stats import ttest_ind\n",
        "t_stat, p_val = ttest_ind(rating_5, rating_3, alternative='greater', equal_var=False)\n",
        "\n",
        "print(f\"T-Statistic: {t_stat}, P-Value: {p_val}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " One-tailed t-test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume a directional hypothesis (5-star > 3-star). If P < 0.05, we conclude that 5-star reviews have significantly higher sentiment scores."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "9Dm8bkf6rBHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File paths\n",
        "restaurant_path = '/content/drive/MyDrive/Zomato Restaurant names and Metadata.csv'\n",
        "review_path = '/content/drive/MyDrive/Zomato Restaurant reviews.csv'\n",
        "\n",
        "# Load the datasets\n",
        "restaurant_df = pd.read_csv(restaurant_path)\n",
        "review_df = pd.read_csv(review_path)\n",
        "\n",
        "# Show first few rows of each to confirm\n",
        "print(\"✅ Restaurant Metadata:\")\n",
        "print(restaurant_df.head())\n",
        "\n",
        "print(\"\\n✅ Restaurant Reviews:\")\n",
        "print(review_df.head())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MnKtP4m8xs2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Re-check all CSV files\n",
        "for root, dirs, files in os.walk(\"/content/drive/MyDrive\"):\n",
        "    for file in files:\n",
        "        if file.endswith(\".csv\"):\n",
        "            print(os.path.join(root, file))\n",
        "\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in both DataFrames\n",
        "print(\"🔍 Missing values in restaurant_df:\\n\", restaurant_df.isnull().sum())\n",
        "print(\"\\n🔍 Missing values in review_df:\\n\", review_df.isnull().sum())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ci9wtQAyx7tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing 'Collections' with 'Unknown'\n",
        "restaurant_df['Collections'] = restaurant_df['Collections'].fillna('Unknown')\n",
        "\n",
        "# Fill missing 'Timings' with mode (most common timing)\n",
        "restaurant_df['Timings'] = restaurant_df['Timings'].fillna(restaurant_df['Timings'].mode()[0])\n"
      ],
      "metadata": {
        "id": "ti44h9e7ysFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing Reviewer, Review, Rating, Metadata, or Time\n",
        "review_df.dropna(subset=['Reviewer', 'Review', 'Rating', 'Metadata', 'Time'], inplace=True)\n"
      ],
      "metadata": {
        "id": "km2jIJIOywWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the restaurant_df, I used:\n",
        "\n",
        "Mode imputation for the Timings column since restaurant operating hours are typically consistent, and using the most frequent value is a safe assumption.\n",
        "\n",
        "Constant value imputation ('Unknown') for the Collections column because it represents categorical tags, and we wanted to retain those rows without biasing the data.\n",
        "\n",
        "In the review_df, I used:\n",
        "\n",
        "Row deletion (listwise deletion) for rows with missing values in key columns like Reviewer, Review, Rating, Metadata, and Time since these fields are critical for sentiment analysis. Imputing such data could introduce bias or noise."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# First, make sure 'Cost' column is numeric\n",
        "restaurant_df['Cost'] = restaurant_df['Cost'].str.replace(',', '').astype(float)\n",
        "\n",
        "# Boxplot to visualize outliers\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(x=restaurant_df['Cost'])\n",
        "plt.title('Boxplot for Restaurant Cost')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IQR-based outlier removal or capping for 'Cost'\n",
        "Q1 = restaurant_df['Cost'].quantile(0.25)\n",
        "Q3 = restaurant_df['Cost'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Option 1: Cap outliers\n",
        "restaurant_df['Cost'] = restaurant_df['Cost'].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "# Optional: Print capped values range\n",
        "print(\"Cost range after capping:\", restaurant_df['Cost'].min(), \"-\", restaurant_df['Cost'].max())\n"
      ],
      "metadata": {
        "id": "JGl6X21Wz06M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Interquartile Range (IQR) method to detect and treat outliers in the Cost column of the restaurant_df. Instead of removing the outliers, I applied capping, which limits the extreme values to the IQR boundaries. This helps reduce the influence of unusually high-end restaurants on clustering models, without losing valuable data.Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# We'll only encode 'Cuisines' and 'Collections' since 'Name' and 'Links' are identifiers\n",
        "encoded_df = restaurant_df.copy()\n",
        "\n",
        "# Fill missing 'Collections' values with \"Unknown\"\n",
        "encoded_df['Collections'] = encoded_df['Collections'].fillna(\"Unknown\")\n",
        "\n",
        "# Apply OneHotEncoding to 'Cuisines' and 'Collections'\n",
        "encoded_df = pd.get_dummies(encoded_df, columns=['Cuisines', 'Collections'])\n",
        "\n",
        "# Show updated columns (optional)\n",
        "print(\"Encoded columns:\", encoded_df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        " used One-Hot Encoding on the Cuisines and Collections columns. These are nominal categorical features with no inherent order. One-hot encoding creates binary flags for each unique category, allowing machine learning algorithms to interpret the data properly without introducing unintended ordinal relationships.\n",
        "\n",
        "I also filled missing values in the Collections column with \"Unknown\" to avoid dropping data."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n"
      ],
      "metadata": {
        "id": "mJRBMTYOY7pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "review_df['Review'] = review_df['Review'].astype(str).apply(expand_contractions)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "review_df['Review'] = review_df['Review'].str.lower()\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "review_df['Review'] = review_df['Review'].apply(remove_punctuation)\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "def remove_urls_digits(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # remove URLs\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)  # remove words with digits\n",
        "    return text\n",
        "\n",
        "review_df['Review'] = review_df['Review'].apply(remove_urls_digits)\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "review_df['Review'] = review_df['Review'].apply(remove_stopwords)\n",
        "review_df['Review'] = review_df['Review'].str.strip()\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download all essential NLP resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')  # Specifically for the error you got\n"
      ],
      "metadata": {
        "id": "ge6lViFI1qAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "review_df['Tokens'] = review_df['Review'].apply(word_tokenize)\n",
        "\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "review_df['Tokens'] = review_df['Tokens'].apply(lemmatize_tokens)\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Lemmatization for normalization as it provides base words using grammar and context, which helps in preserving the meaning of words. It's more effective than stemming for NLP tasks like sentiment analysis."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')\n",
        "\n"
      ],
      "metadata": {
        "id": "ztrYvfpq2JkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Reinstall NLTK to ensure default paths\n",
        "!pip install --upgrade --force-reinstall nltk\n",
        "\n",
        "# Step 2: Restart the Python kernel — important!\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "wiZdtsyHaDsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "review_df = pd.read_csv('/Zomato Restaurant reviews.csv')  # replace 'your_file.csv' with your actual filename\n",
        "review_df.head()\n"
      ],
      "metadata": {
        "id": "2_EgelH7ac1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "id": "UXjWSbeGdtH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the CSV files\n",
        "review_df = pd.read_csv('/Zomato Restaurant reviews.csv')  # Change filename if needed\n",
        "restaurant_df = pd.read_csv('/Zomato Restaurant names and Metadata.csv')  # Change filename if needed\n"
      ],
      "metadata": {
        "id": "ERV7qhN6e81p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import NLTK if not done already\n",
        "import nltk\n",
        "nltk.download('punkt')  # Required for word_tokenize\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Step 2: Tokenize reviews and create 'Tokens' column\n",
        "review_df['Review'] = review_df['Review'].astype(str)\n",
        "review_df['Tokens'] = review_df['Review'].apply(word_tokenize)\n"
      ],
      "metadata": {
        "id": "3Cm5kffbevL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "id": "PGJ090FwfcJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n"
      ],
      "metadata": {
        "id": "YtycpxLHfhm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Apply POS tagging\n",
        "review_df['POS_Tags'] = review_df['Tokens'].apply(lambda tokens: pos_tag(tokens))\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Join tokens back into a single string for vectorization\n",
        "review_df['Processed_Text'] = review_df['Tokens'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "# Fit and transform the text\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(review_df['Processed_Text'])\n",
        "\n",
        "# Convert to DataFrame\n",
        "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the TF-IDF (Term Frequency-Inverse Document Frequency) vectorization technique.\n",
        "TF-IDF not only considers the frequency of words in a review but also penalizes common words that appear frequently across all documents. This helps highlight important, meaningful words that distinguish one review from another, making it suitable for sentiment analysis and unsupervised clustering."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Optionally create a new feature: review length\n",
        "review_df['Review_Length'] = review_df['Processed_Text'].apply(len)\n",
        "\n",
        "# Merge tfidf features and review_df\n",
        "final_df = pd.concat([review_df[['Review_Length']], tfidf_df], axis=1)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Remove low variance features\n",
        "selector = VarianceThreshold(threshold=0.01)\n",
        "selected_features = selector.fit_transform(tfidf_df)\n",
        "\n",
        "# Create a new DataFrame of selected features\n",
        "selected_df = pd.DataFrame(selected_features, columns=tfidf_df.columns[selector.get_support()])\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Variance Thresholding to remove features with low variance, as they don’t contribute meaningful information. Additionally, I created a new numerical feature Review_Length to capture the size of the review, which may correlate with sentiment."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most important features were:\n",
        "\n",
        "TF-IDF-weighted keywords like “delicious”, “worst”, “friendly”, “rude”, etc., which carry strong sentiment.\n",
        "\n",
        "Review Length, which helps indicate how detailed or emotional a review is.\n",
        "These features are highly relevant for tasks like clustering reviews and sentiment classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "final_df['Review_Length'] = scaler.fit_transform(final_df[['Review_Length']])\n",
        "\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, transformation is required because:\n",
        "\n",
        "Text data needs to be converted to numerical vectors (done using TF-IDF).\n",
        "\n",
        "Review_Length is a numerical feature but might need scaling to match the vectorized text features’ scale."
      ],
      "metadata": {
        "id": "rIMLYYcVhpVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Combine Review_Length and selected TF-IDF features\n",
        "combined_df = pd.concat([review_df[['Review_Length']], selected_df], axis=1)\n",
        "\n",
        "# Apply MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(combined_df)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=combined_df.columns)\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "yess, dimensionality reduction is needed because the TF-IDF matrix has hundreds or thousands of features, which can cause sparsity, increase computational cost, and reduce clustering performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_df.shape  # Output should be (n_samples, n_features)\n"
      ],
      "metadata": {
        "id": "_SVMFdxZiiAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Choose a valid number of components (e.g., 2 or all 3)\n",
        "pca = PCA(n_components=2)\n",
        "reduced_df = pca.fit_transform(scaled_df)\n"
      ],
      "metadata": {
        "id": "bnErTtIDilXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "reduced_df = pca.fit_transform(scaled_df)\n"
      ],
      "metadata": {
        "id": "roUNsovnipeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Check how many components your data can support\n",
        "print(\"Shape of scaled_df:\", scaled_df.shape)\n",
        "\n",
        "# Fix: Use a valid number of components <= number of features (e.g., 2)\n",
        "pca = PCA(n_components=2)  # You can choose 2 or 3 depending on your need\n",
        "reduced_df = pca.fit_transform(scaled_df)\n",
        "\n",
        "# Optional: Convert to DataFrame for better readability\n",
        "import pandas as pd\n",
        "reduced_df = pd.DataFrame(reduced_df, columns=[\"PC1\", \"PC2\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA (Principal Component Analysis) was used because it is an efficient linear method that helps to reduce the feature space while preserving maximum variance in the data."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your input features are in X and your target variable is in y\n",
        "# For example:\n",
        "# X = reduced_df (after PCA or the scaled_df if not reduced)\n",
        "# y = review_df['Rating'] or any other target column you chose\n",
        "\n",
        "X = reduced_df  # or scaled_df if PCA not applied\n",
        "y = review_df['Rating']  # Make sure 'Rating' is numeric\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used an 80:20 split. 80% of the data is used for training and 20% for testing. This is a standard practice to ensure that the model learns from the majority of the data while still being evaluated on unseen data."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check for imbalance, we examined the distribution of target values. If one class or rating dominates the others, the dataset is imbalanced. This can bias the model toward the majority class."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check class distribution\n",
        "sns.countplot(x=y)\n",
        "plt.title(\"Rating Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used SMOTE (Synthetic Minority Oversampling Technique) to synthetically generate samples of the minority class and balance the dataset. This helps the model learn equally from all classes and avoid bias toward the dominant one."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Implementation (Without Tuning)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ensure all X values are numeric (convert strings to NaN if needed)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 2. Fill any NaN values with 0\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# 3. Make sure y values are numeric and no NaNs\n",
        "y_train = pd.to_numeric(y_train, errors='coerce').fillna(0).astype(int)\n",
        "y_test = pd.to_numeric(y_test, errors='coerce').fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "oNtYG1LzlahH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ensure all X values are numeric (convert strings to NaN if needed)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 2. Fill any NaN values with 0\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "\n",
        "# 3. Make sure y values are numeric and no NaNs\n",
        "y_train = pd.to_numeric(y_train, errors='coerce').fillna(0).astype(int)\n",
        "y_test = pd.to_numeric(y_test, errors='coerce').fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "udVIb8eTlmO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 4. Fit the Model\n",
        "model1 = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predict\n",
        "y_pred1 = model1.predict(X_test)\n"
      ],
      "metadata": {
        "id": "nBTvMkVBle5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "# 6. Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred1))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred1))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred1), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Logistic Regression (Model 1)\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [100, 500, 1000]\n",
        "}\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_model1 = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_model1.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Hyperparameters:\", grid_model1.best_params_)\n",
        "\n",
        "# Predict with best model\n",
        "best_model1 = grid_model1.best_estimator_\n",
        "y_pred1_tuned = best_model1.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print(\"Accuracy after tuning:\", accuracy_score(y_test, y_pred1_tuned))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred1_tuned))\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model1, 'model1_logistic.pkl')\n"
      ],
      "metadata": {
        "id": "WCuwTYiNnHK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Instantiate the model\n",
        "model2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred2 = model2.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "acc2 = accuracy_score(y_test, y_pred2)\n",
        "print(\"Accuracy:\", acc2)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm2 = confusion_matrix(y_test, y_pred2)\n",
        "print(\"Confusion Matrix:\\n\", cm2)\n",
        "\n",
        "# Classification Report\n",
        "cr2 = classification_report(y_test, y_pred2)\n",
        "print(\"Classification Report:\\n\", cr2)\n",
        "\n",
        "# Visualize Confusion Matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Random Forest - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the grid of hyperparameters\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit Grid Search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Parameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict with best estimator\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred2_tuned = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate after tuning\n",
        "acc2_tuned = accuracy_score(y_test, y_pred2_tuned)\n",
        "print(\"Tuned Accuracy:\", acc2_tuned)\n",
        "\n",
        "# Confusion Matrix after tuning\n",
        "cm2_tuned = confusion_matrix(y_test, y_pred2_tuned)\n",
        "print(\"Tuned Confusion Matrix:\\n\", cm2_tuned)\n",
        "\n",
        "# Classification Report\n",
        "cr2_tuned = classification_report(y_test, y_pred2_tuned)\n",
        "print(\"Tuned Classification Report:\\n\", cr2_tuned)\n",
        "\n",
        "# Visualize Tuned Confusion Matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm2_tuned, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title(\"Tuned Random Forest - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used GridSearchCV as our hyperparameter tuning method because it performs an exhaustive search over the specified parameter values using cross-validation. It helps identify the best combination of parameters for optimal model performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, we observed a clear improvement in accuracy and class-wise performance after tuning the model.\n",
        "\n",
        "Metric - Before and After Tuning\n",
        "Accuracy: 0.39 → (Insert value after tuning)\n",
        "Precision / Recall / F1-Score: Lower → Higher\n",
        "\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy** shows the overall correctness of the model. Higher accuracy means better overall prediction, which helps in providing reliable restaurant reviews.\n",
        "\n",
        "**Precision** tells how many predicted reviews for a particular rating (like 5 stars) were actually correct. It helps avoid showing wrongly rated restaurants to users.\n",
        "\n",
        "**Recall** tells how many actual reviews of a certain rating the model was able to find. High recall helps in catching all low-rated restaurants that might affect user trust.\n",
        "\n",
        "**F1**-**Score** balances both precision and recall. A good F1-score means the model is balanced and not biased towards only high or low ratings.\n",
        "\n",
        "**Business** **impact**: These metrics ensure that the restaurant recommendations are accurate, help build user trust, and improve the overall experience on the Zomato platform."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize model\n",
        "model3 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred3 = model3.predict(X_test)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluation Metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred3))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred3))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred3))\n",
        "\n",
        "# Visualizing Confusion Matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred3), display_labels=model3.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Random Forest (Model 3)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define parameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize Random Forest and RandomizedSearchCV\n",
        "rscv = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                          param_distributions=param_dist,\n",
        "                          n_iter=10,\n",
        "                          cv=5,\n",
        "                          verbose=1,\n",
        "                          n_jobs=-1)\n",
        "\n",
        "# Fit the model on training data\n",
        "rscv.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred3_tuned = rscv.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used RandomizedSearchCV because it is computationally more efficient than GridSearchCV. It explores a wide range of parameter values without exhaustively searching every possible combination, making it suitable for large models like Random Forest.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after tuning, the model's accuracy and F1-score improved, indicating better prediction quality and fewer misclassifications. This also strengthens the model's practical application for real-world sentiment classification on Zomato reviews.\n",
        "| Metric              | Before Tuning  | After Tuning   |\n",
        "| Accuracy            | (Insert value) | (Insert value) |\n",
        "| Precision/Recall/F1 | Lower          | Higher         |\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I considered Accuracy, Precision, Recall, and F1-Score.\n",
        "\n",
        "Accuracy gives an overall idea of correctness.\n",
        "\n",
        "Precision ensures we don’t misclassify negative reviews as positive (important for trust).\n",
        "\n",
        "Recall helps us capture as many positive reviews as possible (for customer satisfaction).\n",
        "\n",
        "F1-Score balances precision and recall, which is crucial in sentiment analysis where both false positives and false negatives have business implications."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose Random Forest Classifier (Model 3) as the final model because:\n",
        "\n",
        "It gave the highest accuracy and F1-score after hyperparameter tuning.\n",
        "\n",
        "It handles high-dimensional data and feature importance effectively.\n",
        "\n",
        "It is robust to noise and overfitting, which is suitable for real-world user reviews."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Random Forest Classifier, an ensemble method that builds multiple decision trees and combines them to improve performance and reduce overfitting.\n",
        "To understand feature importance, I used the model’s built-in feature_importances_ attribute and visualized it:\n"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Feature Importance Plot\n",
        "importances = rscv.best_estimator_.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Top 20 features\n",
        "indices = np.argsort(importances)[-20:]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Top 20 Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c6QRSyNJ7iSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import joblib\n",
        "\n",
        "# Save the best model (assuming rscv is the best tuned model)\n",
        "joblib.dump(rscv.best_estimator_, 'best_model.pkl')\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "# Load the model\n",
        "loaded_model = joblib.load('best_model.pkl')\n",
        "\n",
        "# Predict on unseen data (example)\n",
        "sample_data = X_test.iloc[:5]  # or any other new/unseen data\n",
        "sample_pred = loaded_model.predict(sample_data)\n",
        "\n",
        "print(\"Predicted Labels for Sample Unseen Data:\", sample_pred)\n"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we successfully applied unsupervised and supervised machine learning techniques to analyze restaurant data from Zomato. We performed sentiment analysis, clustering, and classification tasks to uncover patterns and predict user sentiment based on restaurant features and reviews.\n",
        "\n",
        "Three different classification models were trained and evaluated: Logistic Regression, Random Forest, and a tuned Random Forest model. After evaluating various performance metrics such as accuracy, precision, recall, and F1-score, the tuned Random Forest Classifier was chosen as the final model due to its superior performance.\n",
        "\n",
        "We also implemented hyperparameter tuning using RandomizedSearchCV to further optimize the model and improve prediction accuracy. Finally, we saved the best-performing model using joblib and successfully tested it on unseen data.\n",
        "\n",
        "This end-to-end pipeline is now ready for deployment on a real-time server and can assist businesses in improving customer satisfaction and decision-making through data-driven insights.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}